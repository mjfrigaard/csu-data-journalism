---
title: "Introduction to Data Visualization with ggplot2"
comment: "*an introduction to the grammar of graphics*"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    toc_depth: 5
    number_sections: yes
    code_folding: show
    theme: united
    df_print: paged
    
always_allow_html: true
---


```{r remedy01 , include=FALSE}
library(tidyverse)
library(skimr)
# create data folder
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      tidy = FALSE, 
                      fig.height = 5,
                      fig.width = 7,
                      fig.path = "img/")
# set width
options(width = 60)
```

# Objectives 

This document outlines and introduction to data visualization with `ggplot2`. 

# Materials

The slides for this presentation are [here]()

There is also an accompanying [RStudio.Cloud project]()

# Previous lesson contents

You can read more about [`dplyr`](https://dplyr.tidyverse.org/index.html) and [`tidyr`](https://tidyr.tidyverse.org/) on the tidyverse website, and in the [Data Transformation](https://r4ds.had.co.nz/transform.html) and [Tidy Data](https://r4ds.had.co.nz/tidy-data.html) chapters of R for Data Science. 

# Load the packages 

The main packages we're going to use are `dplyr`, `tidyr`, and `ggplot2`. These are all part of the `tidyverse`, so we'll import this package below: 

```{r packages, eval=FALSE}
install.packages("tidyverse")
library(tidyverse)
```

# Import data 

We will begin by importing the data from the wrangling section. These data come from a wikipedia table on [the deployment of COVID-19 vaccinations](https://en.wikipedia.org/wiki/COVID-19_vaccine#Deployment). The code below will scrape the html table and store the results in `COVID19VaxDistByLoc`.

A few things to note about the code below: 

1. We load the `tidyverse`, `rvest`, and `xml2` packages with `library()`   
2. The url for the wikipedia page is read into R with `xml2::read_html()` and stored in `wiki_html` as a list containing `xml_document` and `xml_node`  
3. The `rvest::html_nodes()` function looks for a CSS `"table"` in `wiki_html` and stores these in `wiki_html_tables`  
4. We use the bracket subsetting (`[]`) and `base::grep()` to find tables with the word `"distribution"` in them and store these in `relevant_tables` 
5. Now we can use the `rvest::html_table()` function to 'harvest' the tables stored in the first position of `relevant_tables` and set the `fill` argument to `TRUE` (`[[1]]`), and store the output in `COVID19VaxDistByLoc`. 
6. The `COVID19VaxDistByLoc` is a rectangular `data.frame` object, but we only want the first three columns (`[ , 1:3]`), and we want to rename these `"location"`, `"n_vaccinated"`, and `"perc_of_pop"`.

```{r TopPharmComp, message=FALSE, warning=FALSE}
# packages -----------------------------------------------------------
library(tidyverse)
library(rvest)
library(xml2)

# scrape wikipedia table ---------------------------------------------
# Read html from url
wiki_html <- xml2::read_html("https://en.wikipedia.org/wiki/COVID-19_vaccine")
# extract html nodes
wiki_html_tables <- wiki_html %>% rvest::html_nodes(css = "table")
# identify relevant html table with 'distribution' in the title
relevant_tables <- wiki_html_tables[grep("distribution", wiki_html_tables)]
# convert table to data.frame
COVID19VaxDistByLoc <- rvest::html_table(relevant_tables[[1]],
                                         fill = TRUE)
# assign names to first three columns
COVID19VaxDistByLoc <- COVID19VaxDistByLoc[ , 1:3] %>%
  magrittr::set_names(x = ., value = c("location", "n_vaccinated",
                                       "perc_of_pop"))
glimpse(COVID19VaxDistByLoc)
```

This is a good time to export these data into the `data/raw` folder (in case the numbers change the next time we scrape the table). 

```{r write_csv-raw-data}
readr::write_csv(x = COVID19VaxDistByLoc, 
                 file = paste0("data/raw/", 
                               base::noquote(lubridate::today()),
                 "-COVID19VaxDistByLoc.csv"))
# verify
fs::dir_tree("data/raw/", regexp = "COVID19")
```


## Format variables 

We can see a few of the variables need to be formatted before we can start visualizing. 

```{r head-COVID19VaxDistByLoc}
head(COVID19VaxDistByLoc)
```
1. We need to remove the alphabetic identifier for each country `location` (i.e., `World[d]` and `China[e]`).  
2. The number vaccinated variable (`n_vaccinated`) and percent of population variable (`perc_of_pop`) have symbols (commas (`,`) and percent symbols (`%`)), which is making R treat it as a character, so these will have to be removed and converted to numbers.

First we will identify all the letters in brackets inside the `location` variable using [`stringr::str_view_all()`]()

```{r remedy02}
str_view_all(string = COVID19VaxDistByLoc$location, pattern = "\\[[^\\[\\]]+\\]", match = TRUE)
```

`str_view_all()` shows us all the `locations` with a bracket `[]` + letter/number indicator. Don't worry if you don't know what the regular expression pattern is doing (`"\\[[^\\[\\]]+\\]"`). We will cover regular expressions in a later section (if you can't wait, check out the [Strings chapter of R for Data Science](https://r4ds.had.co.nz/strings.html)).

Now that we've successfully identified the pattern, we can use the 

```{r}
COVID19VaxDistByLoc %>%
  mutate(
    # remove bracket indicators ([])
    location = str_remove_all(string = location, pattern = "\\[[^\\[\\]]+\\]"),
    # 
    # remove whitespace
    stock_id = str_trim(string = stock_id, side = "both")) -> TopPharmComp
```

